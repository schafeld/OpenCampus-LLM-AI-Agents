{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6eaee2fe-9dd7-4d9f-828c-148f8b257eea",
   "metadata": {},
   "source": [
    "# Langchain RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d639468-9256-4db4-8ddf-75c1efbddd46",
   "metadata": {},
   "source": [
    "A typical RAG application has two main components:\n",
    "\n",
    "**Indexing**: a pipeline for ingesting data from a source and indexing it. This usually happens offline.\n",
    "\n",
    "**Retrieval and generation**: the actual RAG chain, which takes the user query at run time and retrieves the relevant data from the index, then passes that to the model.\n",
    "\n",
    "The most common full sequence from raw data to answer looks like:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5335f758-3e24-44ae-93c6-3adfe1e1e030",
   "metadata": {},
   "source": [
    "### Indexing\n",
    "1. **Load**: First we need to load our data. This is done in langchain with Document Loaders classes.\n",
    "2. **Split**: Text splitters break large Documents into smaller chunks. This is necessary because embedding models have a finite context window.\n",
    "3. **Embed**: Then we need to convert those chunks into vectors. This is done with an embedding model.\n",
    "4. **Store**: We need somewhere to store and index our vectors from the text chunks, so that we can search over them later. This is done using a VectorStore."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ae9c94-2f9f-4f6e-98c1-0f3fb00bb0d0",
   "metadata": {},
   "source": [
    "### Retrieval and generation\n",
    "5. **Retrieve**: Given a user input, relevant splits are retrieved from storage using a Retriever.\n",
    "6. **Generate**: A LLM produces an answer using a prompt that includes both the question and the retrieved data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319ead7f-f0b0-422d-8dfa-0f67e8f6e80b",
   "metadata": {},
   "source": [
    "![Indexing pipeline](./indexing-pipeline.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce420411-1260-4bdf-9fc5-666d29ca9f8a",
   "metadata": {},
   "source": [
    "Prepare to import your API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ae3b5ba-fd14-4ecc-8e4c-8100e21e9e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /Users/user001/anaconda3/lib/python3.11/site-packages (0.21.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce1ccaf7-b1d0-4e96-8c89-833ed72fb7d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-openai in /Users/user001/anaconda3/lib/python3.11/site-packages (0.3.16)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in /Users/user001/anaconda3/lib/python3.11/site-packages (from langchain-openai) (0.3.58)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.68.2 in /Users/user001/anaconda3/lib/python3.11/site-packages (from langchain-openai) (1.77.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /Users/user001/anaconda3/lib/python3.11/site-packages (from langchain-openai) (0.9.0)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /Users/user001/anaconda3/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain-openai) (0.3.42)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/user001/anaconda3/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain-openai) (8.2.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/user001/anaconda3/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain-openai) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/user001/anaconda3/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain-openai) (6.0)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/user001/anaconda3/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain-openai) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/user001/anaconda3/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain-openai) (4.13.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /Users/user001/anaconda3/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain-openai) (2.11.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/user001/anaconda3/lib/python3.11/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (3.5.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/user001/anaconda3/lib/python3.11/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/user001/anaconda3/lib/python3.11/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/user001/anaconda3/lib/python3.11/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (0.9.0)\n",
      "Requirement already satisfied: sniffio in /Users/user001/anaconda3/lib/python3.11/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.2.0)\n",
      "Requirement already satisfied: tqdm>4 in /Users/user001/anaconda3/lib/python3.11/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.65.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/user001/anaconda3/lib/python3.11/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2022.7.9)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/user001/anaconda3/lib/python3.11/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2.31.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/user001/anaconda3/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.68.2->langchain-openai) (3.4)\n",
      "Requirement already satisfied: certifi in /Users/user001/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain-openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/user001/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain-openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/user001/anaconda3/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/user001/anaconda3/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain-openai) (2.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/user001/anaconda3/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.58->langchain-openai) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/user001/anaconda3/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.58->langchain-openai) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/user001/anaconda3/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.58->langchain-openai) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/user001/anaconda3/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.58->langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /Users/user001/anaconda3/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.58->langchain-openai) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/user001/anaconda3/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.58->langchain-openai) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/user001/anaconda3/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/user001/anaconda3/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (1.26.16)\n"
     ]
    }
   ],
   "source": [
    "#pip install langchain\n",
    "!pip install -U langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe95504-6ec4-4adf-840b-43a170a7656e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(os.path.expanduser(\"~/Projekte/MOOC/OpenCampus/codespace/.env\"))\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  # os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "  raise EnvironmentError(\"OPENAI_API_KEY not found in the .env file.\")\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c2c3baa-a26c-4302-8531-ab8777663822",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "882c2e35-cd7f-4657-aa8d-cf74b863a2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "vector_store = InMemoryVectorStore(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b8f1b5-3aa5-4cd8-bd4b-95d3fc21ed53",
   "metadata": {},
   "source": [
    "In this guide we’ll build an app that answers questions about the website's content. The specific website we will use is the [LLM Powered Autonomous Agents](https://lilianweng.github.io/posts/2023-06-23-agent/) blog post by Lilian Weng, which allows us to ask questions about the contents of the post.\n",
    "\n",
    "We can create a simple indexing pipeline and RAG chain to do this in ~50 lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7de32ae1-6827-454a-b1c0-6498274d3010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-text-splitters in /Users/user001/anaconda3/lib/python3.11/site-packages (0.3.8)\n",
      "Requirement already satisfied: langchain-community in /Users/user001/anaconda3/lib/python3.11/site-packages (0.3.23)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in /Users/user001/anaconda3/lib/python3.11/site-packages (from langchain-text-splitters) (0.3.58)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.24 in /Users/user001/anaconda3/lib/python3.11/site-packages (from langchain-community) (0.3.25)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/user001/anaconda3/lib/python3.11/site-packages (from langchain-community) (2.0.35)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/user001/anaconda3/lib/python3.11/site-packages (from langchain-community) (2.31.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/user001/anaconda3/lib/python3.11/site-packages (from langchain-community) (6.0)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/user001/anaconda3/lib/python3.11/site-packages (from langchain-community) (3.8.5)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /Users/user001/anaconda3/lib/python3.11/site-packages (from langchain-community) (8.2.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/user001/anaconda3/lib/python3.11/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /Users/user001/anaconda3/lib/python3.11/site-packages (from langchain-community) (2.9.1)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /Users/user001/anaconda3/lib/python3.11/site-packages (from langchain-community) (0.3.42)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /Users/user001/anaconda3/lib/python3.11/site-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /Users/user001/anaconda3/lib/python3.11/site-packages (from langchain-community) (2.2.5)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/user001/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/user001/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/user001/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/user001/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/user001/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/user001/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/user001/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.2.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/user001/anaconda3/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.22.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/user001/anaconda3/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/user001/anaconda3/lib/python3.11/site-packages (from langchain<1.0.0,>=0.3.24->langchain-community) (2.11.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/user001/anaconda3/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.51->langchain-text-splitters) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/user001/anaconda3/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.51->langchain-text-splitters) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/user001/anaconda3/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.51->langchain-text-splitters) (4.13.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/user001/anaconda3/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/user001/anaconda3/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/user001/anaconda3/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/user001/anaconda3/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /Users/user001/anaconda3/lib/python3.11/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.21.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/user001/anaconda3/lib/python3.11/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/user001/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain-community) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/user001/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain-community) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/user001/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain-community) (2025.1.31)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/user001/anaconda3/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (2.0.1)\n",
      "Requirement already satisfied: anyio in /Users/user001/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (3.5.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/user001/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.5)\n",
      "Requirement already satisfied: sniffio in /Users/user001/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.2.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/user001/anaconda3/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/user001/anaconda3/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain-text-splitters) (2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/user001/anaconda3/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.24->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /Users/user001/anaconda3/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.24->langchain-community) (2.33.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/user001/anaconda3/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-text-splitters langchain-community"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce81afbb-afc6-4de0-bd0e-1f236cbf9f7e",
   "metadata": {},
   "source": [
    " Load & Split Your Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0e663a7-3811-4a33-a216-61fab567a6f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ca7b322-f4cd-444d-b25d-6a5e5794845a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and chunk contents of the blog\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "all_splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb1acff-8273-4097-8dcc-305ae133dbfe",
   "metadata": {},
   "source": [
    "Embed & Store Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99292a59-694b-4ae8-8c75-ed093549d383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index chunks\n",
    "_ = vector_store.add_documents(documents=all_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3138907f-08c6-4dca-8c3c-48d97d7d9927",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(\n",
    "    search_type = \"similarity\",     # \"mmr\" or \"similarity_score_threshold\" also work\n",
    "    search_kwargs = {\"k\": 4}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d71ca238-266a-467b-8299-80641c0d23bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "SYSTEM = \"\"\"You are an expert assistant.\n",
    "Answer *only* from the context between <context></context>;\n",
    "if the answer isn’t there, say “I don't know.”\"\"\"\n",
    "USER = \"\"\"<context>\\n{context}\\n</context>\\n\\nQuestion: {input}\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([(\"system\", SYSTEM), (\"user\", USER)])\n",
    "\n",
    "# NEW: wrap llm + prompt in a \"stuff-documents\" chain → Runnable\n",
    "combine_docs_chain = create_stuff_documents_chain(llm, prompt)  \n",
    "\n",
    "# Build the final RAG runnable\n",
    "rag_chain = create_retrieval_chain(retriever, combine_docs_chain) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bd7410e8-75ad-4982-a009-1e9f68ad021a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task Decomposition is a process where a complicated task is broken down into smaller and simpler steps. This can be achieved through methods such as Chain of Thought (CoT), which instructs the model to “think step by step” to decompose hard tasks, or via Tree of Thoughts, which explores multiple reasoning possibilities at each step by generating multiple thoughts per step, creating a tree structure. Task decomposition can be performed by the LLM using simple prompts, task-specific instructions, or with human inputs.\n",
      "[Document(id='a7201102-3297-4187-9676-858646ae206c', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.'), Document(id='8e200f57-5c9c-4567-98b4-07837607662d', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.'), Document(id='745a1084-e608-455c-a3d1-b0910fda97c8', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='The AI assistant can parse user input to several tasks: [{\"task\": task, \"id\", task_id, \"dep\": dependency_task_ids, \"args\": {\"text\": text, \"image\": URL, \"audio\": URL, \"video\": URL}}]. The \"dep\" field denotes the id of the previous task which generates a new resource that the current task relies on. A special tag \"-task_id\" refers to the generated text image, audio and video in the dependency task with id as task_id. The task MUST be selected from the following options: {{ Available Task List }}. There is a logical relationship between tasks, please note their order. If the user input can\\'t be parsed, you need to reply empty JSON. Here are several cases for your reference: {{ Demonstrations }}. The chat history is recorded as {{ Chat History }}. From this chat history, you can find the path of the user-mentioned resources for your task planning.'), Document(id='093d9da4-6b78-45fa-8393-ef51656e5a32', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Fig. 11. Illustration of how HuggingGPT works. (Image source: Shen et al. 2023)\\nThe system comprises of 4 stages:\\n(1) Task planning: LLM works as the brain and parses the user requests into multiple tasks. There are four attributes associated with each task: task type, ID, dependencies, and arguments. They use few-shot examples to guide LLM to do task parsing and planning.\\nInstruction:')]\n"
     ]
    }
   ],
   "source": [
    "question = \"What is Task Decomposition?\"\n",
    "result   = rag_chain.invoke({\"input\": question})\n",
    "\n",
    "print(result[\"answer\"])      # grounded answer\n",
    "print(result[\"context\"])     # the stuffed context string (if you need sources, see below)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09dfc3e-d18e-4e9e-8b43-0977c02933ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
