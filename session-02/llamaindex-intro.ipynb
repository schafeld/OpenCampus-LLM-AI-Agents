{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25c75732-3e10-48c9-89d3-dd43595bbc3d",
   "metadata": {},
   "source": [
    "# First llamaindex tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b5a67c-fc98-44c2-b534-b20025276e51",
   "metadata": {},
   "source": [
    "Prepare to import your API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77edabf7-09fb-4f4c-9930-f75b522ef2db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /Users/user001/anaconda3/lib/python3.11/site-packages (0.21.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7865bf-2c6d-4fb0-84a9-d6bb4ffd2f5a",
   "metadata": {},
   "source": [
    "Similar to langchain llamaindex provides a lot of functionality to easily work with LLMs. It is one of the most popular frameworks besides langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53499eb2-dacd-4395-ba3b-e413492d1444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index\n",
      "  Obtaining dependency information for llama-index from https://files.pythonhosted.org/packages/17/3c/6ac00c9fb5d9811499badc524cc27c0a199cfe675fa67bdbe63c115bac7a/llama_index-0.12.34-py3-none-any.whl.metadata\n",
      "  Downloading llama_index-0.12.34-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting llama-index-agent-openai<0.5,>=0.4.0 (from llama-index)\n",
      "  Obtaining dependency information for llama-index-agent-openai<0.5,>=0.4.0 from https://files.pythonhosted.org/packages/ea/00/707a40dc626ff47b00735fb3da844564f7b5f83c53733e9671de8d77abf5/llama_index_agent_openai-0.4.7-py3-none-any.whl.metadata\n",
      "  Downloading llama_index_agent_openai-0.4.7-py3-none-any.whl.metadata (438 bytes)\n",
      "Collecting llama-index-cli<0.5,>=0.4.1 (from llama-index)\n",
      "  Obtaining dependency information for llama-index-cli<0.5,>=0.4.1 from https://files.pythonhosted.org/packages/ae/fa/2ee58764d733e9b5d61036ba6c8c96adcdb567ea16a62c247519fbf34c13/llama_index_cli-0.4.1-py3-none-any.whl.metadata\n",
      "  Downloading llama_index_cli-0.4.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting llama-index-core<0.13,>=0.12.34 (from llama-index)\n",
      "  Obtaining dependency information for llama-index-core<0.13,>=0.12.34 from https://files.pythonhosted.org/packages/4f/c0/876dad0daa4493bb30d823933a0b916e3c294a46b9f15eaa40264b559ff9/llama_index_core-0.12.34.post1-py3-none-any.whl.metadata\n",
      "  Downloading llama_index_core-0.12.34.post1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting llama-index-embeddings-openai<0.4,>=0.3.0 (from llama-index)\n",
      "  Obtaining dependency information for llama-index-embeddings-openai<0.4,>=0.3.0 from https://files.pythonhosted.org/packages/bb/45/ca55b91c4ac1b6251d4099fa44121a6c012129822906cadcc27b8cfb33a4/llama_index_embeddings_openai-0.3.1-py3-none-any.whl.metadata\n",
      "  Downloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl.metadata (684 bytes)\n",
      "Collecting llama-index-indices-managed-llama-cloud>=0.4.0 (from llama-index)\n",
      "  Obtaining dependency information for llama-index-indices-managed-llama-cloud>=0.4.0 from https://files.pythonhosted.org/packages/7e/f4/5decd79fd7f2f0e44c5689af62497447e86832e876b7dad11903259de5f9/llama_index_indices_managed_llama_cloud-0.6.11-py3-none-any.whl.metadata\n",
      "  Downloading llama_index_indices_managed_llama_cloud-0.6.11-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting llama-index-llms-openai<0.4,>=0.3.0 (from llama-index)\n",
      "  Obtaining dependency information for llama-index-llms-openai<0.4,>=0.3.0 from https://files.pythonhosted.org/packages/e4/e1/1c185e22ca1fd1ac813d225be046c4223dbe2fdf64d90a6e86608e6d17ad/llama_index_llms_openai-0.3.38-py3-none-any.whl.metadata\n",
      "  Downloading llama_index_llms_openai-0.3.38-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-index-multi-modal-llms-openai<0.5,>=0.4.0 (from llama-index)\n",
      "  Obtaining dependency information for llama-index-multi-modal-llms-openai<0.5,>=0.4.0 from https://files.pythonhosted.org/packages/75/90/7a5a44959192b739718618d6fbfb5be8d21909dbd81865b9d4bb45a8bc89/llama_index_multi_modal_llms_openai-0.4.3-py3-none-any.whl.metadata\n",
      "  Downloading llama_index_multi_modal_llms_openai-0.4.3-py3-none-any.whl.metadata (726 bytes)\n",
      "Collecting llama-index-program-openai<0.4,>=0.3.0 (from llama-index)\n",
      "  Obtaining dependency information for llama-index-program-openai<0.4,>=0.3.0 from https://files.pythonhosted.org/packages/00/59/3f31171c30a08c8ba21155d5241ba174630e57cf43b03d97fd77bf565b51/llama_index_program_openai-0.3.1-py3-none-any.whl.metadata\n",
      "  Downloading llama_index_program_openai-0.3.1-py3-none-any.whl.metadata (764 bytes)\n",
      "Collecting llama-index-question-gen-openai<0.4,>=0.3.0 (from llama-index)\n",
      "  Obtaining dependency information for llama-index-question-gen-openai<0.4,>=0.3.0 from https://files.pythonhosted.org/packages/7c/2c/765b0dfc2c988bbea267e236c836d7a96c60a20df76d842e43e17401f800/llama_index_question_gen_openai-0.3.0-py3-none-any.whl.metadata\n",
      "  Downloading llama_index_question_gen_openai-0.3.0-py3-none-any.whl.metadata (783 bytes)\n",
      "Collecting llama-index-readers-file<0.5,>=0.4.0 (from llama-index)\n",
      "  Obtaining dependency information for llama-index-readers-file<0.5,>=0.4.0 from https://files.pythonhosted.org/packages/53/8c/d40d3dbee8012b320aacfdeb131e834bc37f3cb2b978a514d2ff5c4ffd47/llama_index_readers_file-0.4.7-py3-none-any.whl.metadata\n",
      "  Downloading llama_index_readers_file-0.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting llama-index-readers-llama-parse>=0.4.0 (from llama-index)\n",
      "  Obtaining dependency information for llama-index-readers-llama-parse>=0.4.0 from https://files.pythonhosted.org/packages/68/4f/e30d4257fe9e4224f5612b77fe99aaceddae411b2e74ca30534491de3e6f/llama_index_readers_llama_parse-0.4.0-py3-none-any.whl.metadata\n",
      "  Downloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting nltk>3.8.1 (from llama-index)\n",
      "  Obtaining dependency information for nltk>3.8.1 from https://files.pythonhosted.org/packages/4d/66/7d9e26593edda06e8cb531874633f7c2372279c3b0f46235539fe546df8b/nltk-3.9.1-py3-none-any.whl.metadata\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: openai>=1.14.0 in /Users/user001/anaconda3/lib/python3.11/site-packages (from llama-index-agent-openai<0.5,>=0.4.0->llama-index) (1.77.0)\n",
      "Collecting aiohttp<4,>=3.8.6 (from llama-index-core<0.13,>=0.12.34->llama-index)\n",
      "  Obtaining dependency information for aiohttp<4,>=3.8.6 from https://files.pythonhosted.org/packages/22/eb/6a77f055ca56f7aae2cd2a5607a3c9e7b9554f1497a069dcfcb52bfc9540/aiohttp-3.11.18-cp311-cp311-macosx_10_9_x86_64.whl.metadata\n",
      "  Downloading aiohttp-3.11.18-cp311-cp311-macosx_10_9_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting banks<3,>=2.0.0 (from llama-index-core<0.13,>=0.12.34->llama-index)\n",
      "  Obtaining dependency information for banks<3,>=2.0.0 from https://files.pythonhosted.org/packages/04/4a/7fdca29d1db62f5f5c3446bf8f668beacdb0b5a8aff4247574ddfddc6bcd/banks-2.1.2-py3-none-any.whl.metadata\n",
      "  Downloading banks-2.1.2-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: dataclasses-json in /Users/user001/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.34->llama-index) (0.6.7)\n",
      "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.13,>=0.12.34->llama-index)\n",
      "  Obtaining dependency information for deprecated>=1.2.9.3 from https://files.pythonhosted.org/packages/6e/c6/ac0b6c1e2d138f1002bcf799d330bd6d85084fece321e662a14223794041/Deprecated-1.2.18-py2.py3-none-any.whl.metadata\n",
      "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting dirtyjson<2,>=1.0.8 (from llama-index-core<0.13,>=0.12.34->llama-index)\n",
      "  Obtaining dependency information for dirtyjson<2,>=1.0.8 from https://files.pythonhosted.org/packages/68/69/1bcf70f81de1b4a9f21b3a62ec0c83bdff991c88d6cc2267d02408457e88/dirtyjson-1.0.8-py3-none-any.whl.metadata\n",
      "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting filetype<2,>=1.2.0 (from llama-index-core<0.13,>=0.12.34->llama-index)\n",
      "  Obtaining dependency information for filetype<2,>=1.2.0 from https://files.pythonhosted.org/packages/18/79/1b8fa1bb3568781e84c9200f951c735f3f157429f44be0495da55894d620/filetype-1.2.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting fsspec>=2023.5.0 (from llama-index-core<0.13,>=0.12.34->llama-index)\n",
      "  Obtaining dependency information for fsspec>=2023.5.0 from https://files.pythonhosted.org/packages/44/4b/e0cfc1a6f17e990f3e64b7d941ddc4acdc7b19d6edd51abf495f32b1a9e4/fsspec-2025.3.2-py3-none-any.whl.metadata\n",
      "  Downloading fsspec-2025.3.2-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: httpx in /Users/user001/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.34->llama-index) (0.27.0)\n",
      "Collecting nest-asyncio<2,>=1.5.8 (from llama-index-core<0.13,>=0.12.34->llama-index)\n",
      "  Obtaining dependency information for nest-asyncio<2,>=1.5.8 from https://files.pythonhosted.org/packages/a0/c4/c2971a3ba4c6103a3d10c4b0f24f461ddc027f0f09763220cf35ca1401b3/nest_asyncio-1.6.0-py3-none-any.whl.metadata\n",
      "  Downloading nest_asyncio-1.6.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/user001/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.34->llama-index) (3.1)\n",
      "Requirement already satisfied: numpy in /Users/user001/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.34->llama-index) (2.2.5)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Users/user001/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.34->llama-index) (10.0.1)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in /Users/user001/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.34->llama-index) (2.11.3)\n",
      "Collecting pyyaml>=6.0.1 (from llama-index-core<0.13,>=0.12.34->llama-index)\n",
      "  Obtaining dependency information for pyyaml>=6.0.1 from https://files.pythonhosted.org/packages/f8/aa/7af4e81f7acba21a4c6be026da38fd2b872ca46226673c89a758ebdc4fd2/PyYAML-6.0.2-cp311-cp311-macosx_10_9_x86_64.whl.metadata\n",
      "  Downloading PyYAML-6.0.2-cp311-cp311-macosx_10_9_x86_64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: requests>=2.31.0 in /Users/user001/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.34->llama-index) (2.31.0)\n",
      "Requirement already satisfied: sqlalchemy[asyncio]>=1.4.49 in /Users/user001/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.34->llama-index) (2.0.35)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /Users/user001/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.34->llama-index) (8.2.2)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /Users/user001/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.34->llama-index) (0.9.0)\n",
      "Collecting tqdm<5,>=4.66.1 (from llama-index-core<0.13,>=0.12.34->llama-index)\n",
      "  Obtaining dependency information for tqdm<5,>=4.66.1 from https://files.pythonhosted.org/packages/d0/30/dc54f88dd4a2b5dc8a0279bdd7270e735851848b762aeb1c1184ed1f6b14/tqdm-4.67.1-py3-none-any.whl.metadata\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /Users/user001/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.34->llama-index) (4.13.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/user001/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.34->llama-index) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /Users/user001/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.34->llama-index) (1.14.1)\n",
      "Collecting llama-cloud<0.2.0,>=0.1.13 (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index)\n",
      "  Obtaining dependency information for llama-cloud<0.2.0,>=0.1.13 from https://files.pythonhosted.org/packages/db/d5/550bcd5a1e29f87a026d8d90ff011f5bf40f835799c61f38d995dc3e488d/llama_cloud-0.1.20-py3-none-any.whl.metadata\n",
      "  Downloading llama_cloud-0.1.20-py3-none-any.whl.metadata (914 bytes)\n",
      "Collecting beautifulsoup4<5.0.0,>=4.12.3 (from llama-index-readers-file<0.5,>=0.4.0->llama-index)\n",
      "  Obtaining dependency information for beautifulsoup4<5.0.0,>=4.12.3 from https://files.pythonhosted.org/packages/50/cd/30110dc0ffcf3b131156077b90e9f60ed75711223f306da4db08eff8403b/beautifulsoup4-4.13.4-py3-none-any.whl.metadata\n",
      "  Downloading beautifulsoup4-4.13.4-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: pandas in /Users/user001/anaconda3/lib/python3.11/site-packages (from llama-index-readers-file<0.5,>=0.4.0->llama-index) (2.0.3)\n",
      "Collecting pypdf<6.0.0,>=5.1.0 (from llama-index-readers-file<0.5,>=0.4.0->llama-index)\n",
      "  Obtaining dependency information for pypdf<6.0.0,>=5.1.0 from https://files.pythonhosted.org/packages/0b/27/d83f8f2a03ca5408dc2cc84b49c0bf3fbf059398a6a2ea7c10acfe28859f/pypdf-5.4.0-py3-none-any.whl.metadata\n",
      "  Downloading pypdf-5.4.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.5,>=0.4.0->llama-index)\n",
      "  Obtaining dependency information for striprtf<0.0.27,>=0.0.26 from https://files.pythonhosted.org/packages/a3/cf/0fea4f4ba3fc2772ac2419278aa9f6964124d4302117d61bc055758e000c/striprtf-0.0.26-py3-none-any.whl.metadata\n",
      "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Obtaining dependency information for llama-parse>=0.5.0 from https://files.pythonhosted.org/packages/67/72/cccdac06596fb1dcc53bb8114580d80081f0043e065bea468c935cbeec7e/llama_parse-0.6.21-py3-none-any.whl.metadata\n",
      "  Downloading llama_parse-0.6.21-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: click in /Users/user001/anaconda3/lib/python3.11/site-packages (from nltk>3.8.1->llama-index) (8.1.8)\n",
      "Requirement already satisfied: joblib in /Users/user001/anaconda3/lib/python3.11/site-packages (from nltk>3.8.1->llama-index) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/user001/anaconda3/lib/python3.11/site-packages (from nltk>3.8.1->llama-index) (2022.7.9)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.34->llama-index)\n",
      "  Obtaining dependency information for aiohappyeyeballs>=2.3.0 from https://files.pythonhosted.org/packages/0f/15/5bf3b99495fb160b63f95972b81750f18f7f4e02ad051373b669d17d44f2/aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/user001/anaconda3/lib/python3.11/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.34->llama-index) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/user001/anaconda3/lib/python3.11/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.34->llama-index) (22.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/user001/anaconda3/lib/python3.11/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.34->llama-index) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/user001/anaconda3/lib/python3.11/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.34->llama-index) (6.0.2)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.34->llama-index)\n",
      "  Obtaining dependency information for propcache>=0.2.0 from https://files.pythonhosted.org/packages/ce/84/3db5537e0879942783e2256616ff15d870a11d7ac26541336fe1b673c818/propcache-0.3.1-cp311-cp311-macosx_10_9_x86_64.whl.metadata\n",
      "  Downloading propcache-0.3.1-cp311-cp311-macosx_10_9_x86_64.whl.metadata (10 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.34->llama-index)\n",
      "  Obtaining dependency information for yarl<2.0,>=1.17.0 from https://files.pythonhosted.org/packages/ba/81/315a3f6f95947cfbf37c92d6fbce42a1a6207b6c38e8c2b452499ec7d449/yarl-1.20.0-cp311-cp311-macosx_10_9_x86_64.whl.metadata\n",
      "  Downloading yarl-1.20.0-cp311-cp311-macosx_10_9_x86_64.whl.metadata (72 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.4/72.4 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting griffe (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.34->llama-index)\n",
      "  Obtaining dependency information for griffe from https://files.pythonhosted.org/packages/58/c6/5c20af38c2a57c15d87f7f38bee77d63c1d2a3689f74fefaf35915dd12b2/griffe-1.7.3-py3-none-any.whl.metadata\n",
      "  Downloading griffe-1.7.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: jinja2 in /Users/user001/anaconda3/lib/python3.11/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.34->llama-index) (3.1.2)\n",
      "Requirement already satisfied: platformdirs in /Users/user001/anaconda3/lib/python3.11/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.34->llama-index) (3.10.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/user001/anaconda3/lib/python3.11/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5,>=0.4.0->llama-index) (2.4)\n",
      "Requirement already satisfied: certifi>=2024.7.4 in /Users/user001/anaconda3/lib/python3.11/site-packages (from llama-cloud<0.2.0,>=0.1.13->llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (2025.1.31)\n",
      "Requirement already satisfied: anyio in /Users/user001/anaconda3/lib/python3.11/site-packages (from httpx->llama-index-core<0.13,>=0.12.34->llama-index) (3.5.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/user001/anaconda3/lib/python3.11/site-packages (from httpx->llama-index-core<0.13,>=0.12.34->llama-index) (1.0.5)\n",
      "Requirement already satisfied: idna in /Users/user001/anaconda3/lib/python3.11/site-packages (from httpx->llama-index-core<0.13,>=0.12.34->llama-index) (3.4)\n",
      "Requirement already satisfied: sniffio in /Users/user001/anaconda3/lib/python3.11/site-packages (from httpx->llama-index-core<0.13,>=0.12.34->llama-index) (1.2.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/user001/anaconda3/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13,>=0.12.34->llama-index) (0.14.0)\n",
      "Collecting llama-cloud-services>=0.6.21 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Obtaining dependency information for llama-cloud-services>=0.6.21 from https://files.pythonhosted.org/packages/91/12/8485afc9813574f0a1c9ca28df5dffa10e2fefa6cefddc73f4b3e36f0a5e/llama_cloud_services-0.6.21-py3-none-any.whl.metadata\n",
      "  Downloading llama_cloud_services-0.6.21-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/user001/anaconda3/lib/python3.11/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/user001/anaconda3/lib/python3.11/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (0.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/user001/anaconda3/lib/python3.11/site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.34->llama-index) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /Users/user001/anaconda3/lib/python3.11/site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.34->llama-index) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/user001/anaconda3/lib/python3.11/site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.34->llama-index) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/user001/anaconda3/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.34->llama-index) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/user001/anaconda3/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.34->llama-index) (1.26.16)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/user001/anaconda3/lib/python3.11/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.34->llama-index) (2.0.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/user001/anaconda3/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13,>=0.12.34->llama-index) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/user001/anaconda3/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.13,>=0.12.34->llama-index) (3.22.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/user001/anaconda3/lib/python3.11/site-packages (from pandas->llama-index-readers-file<0.5,>=0.4.0->llama-index) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/user001/anaconda3/lib/python3.11/site-packages (from pandas->llama-index-readers-file<0.5,>=0.4.0->llama-index) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/user001/anaconda3/lib/python3.11/site-packages (from pandas->llama-index-readers-file<0.5,>=0.4.0->llama-index) (2023.3)\n",
      "Collecting llama-cloud<0.2.0,>=0.1.13 (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index)\n",
      "  Obtaining dependency information for llama-cloud<0.2.0,>=0.1.13 from https://files.pythonhosted.org/packages/04/55/4d66e57a81b9b9b5c43e962c8a032f6b9b43fac40dc32e2fe3943ad5df7f/llama_cloud-0.1.19-py3-none-any.whl.metadata\n",
      "  Downloading llama_cloud-0.1.19-py3-none-any.whl.metadata (902 bytes)\n",
      "Collecting platformdirs (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.34->llama-index)\n",
      "  Obtaining dependency information for platformdirs from https://files.pythonhosted.org/packages/6d/45/59578566b3275b8fd9157885918fcd0c4d74162928a5310926887b856a51/platformdirs-4.3.7-py3-none-any.whl.metadata\n",
      "  Downloading platformdirs-4.3.7-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting python-dotenv<2.0.0,>=1.0.1 (from llama-cloud-services>=0.6.21->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Obtaining dependency information for python-dotenv<2.0.0,>=1.0.1 from https://files.pythonhosted.org/packages/1e/18/98a99ad95133c6a6e2005fe89faedf294a748bd5dc803008059409ac9b1e/python_dotenv-1.1.0-py3-none-any.whl.metadata\n",
      "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/user001/anaconda3/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13,>=0.12.34->llama-index) (24.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/user001/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-readers-file<0.5,>=0.4.0->llama-index) (1.16.0)\n",
      "Requirement already satisfied: colorama>=0.4 in /Users/user001/anaconda3/lib/python3.11/site-packages (from griffe->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.34->llama-index) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/user001/anaconda3/lib/python3.11/site-packages (from jinja2->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.34->llama-index) (2.1.1)\n",
      "Downloading llama_index-0.12.34-py3-none-any.whl (7.0 kB)\n",
      "Downloading llama_index_agent_openai-0.4.7-py3-none-any.whl (14 kB)\n",
      "Downloading llama_index_cli-0.4.1-py3-none-any.whl (28 kB)\n",
      "Downloading llama_index_core-0.12.34.post1-py3-none-any.whl (7.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl (6.2 kB)\n",
      "Downloading llama_index_indices_managed_llama_cloud-0.6.11-py3-none-any.whl (14 kB)\n",
      "Downloading llama_index_llms_openai-0.3.38-py3-none-any.whl (23 kB)\n",
      "Downloading llama_index_multi_modal_llms_openai-0.4.3-py3-none-any.whl (5.9 kB)\n",
      "Downloading llama_index_program_openai-0.3.1-py3-none-any.whl (5.3 kB)\n",
      "Downloading llama_index_question_gen_openai-0.3.0-py3-none-any.whl (2.9 kB)\n",
      "Downloading llama_index_readers_file-0.4.7-py3-none-any.whl (40 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl (2.5 kB)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.11.18-cp311-cp311-macosx_10_9_x86_64.whl (471 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.4/471.4 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading banks-2.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading beautifulsoup4-4.13.4-py3-none-any.whl (187 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m187.3/187.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
      "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading llama_parse-0.6.21-py3-none-any.whl (4.9 kB)\n",
      "Downloading nest_asyncio-1.6.0-py3-none-any.whl (5.2 kB)\n",
      "Downloading pypdf-5.4.0-py3-none-any.whl (302 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.3/302.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading PyYAML-6.0.2-cp311-cp311-macosx_10_9_x86_64.whl (184 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.6/184.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading llama_cloud_services-0.6.21-py3-none-any.whl (37 kB)\n",
      "Downloading llama_cloud-0.1.19-py3-none-any.whl (263 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m263.6/263.6 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading platformdirs-4.3.7-py3-none-any.whl (18 kB)\n",
      "Downloading propcache-0.3.1-cp311-cp311-macosx_10_9_x86_64.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.5/46.5 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading yarl-1.20.0-cp311-cp311-macosx_10_9_x86_64.whl (96 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.9/96.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading griffe-1.7.3-py3-none-any.whl (129 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.3/129.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: striprtf, filetype, dirtyjson, tqdm, pyyaml, python-dotenv, pypdf, propcache, platformdirs, nest-asyncio, griffe, fsspec, deprecated, beautifulsoup4, aiohappyeyeballs, yarl, nltk, llama-cloud, banks, aiohttp, llama-index-core, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-cloud-services, llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-readers-llama-parse, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.65.0\n",
      "    Uninstalling tqdm-4.65.0:\n",
      "      Successfully uninstalled tqdm-4.65.0\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 6.0\n",
      "    Uninstalling PyYAML-6.0:\n",
      "      Successfully uninstalled PyYAML-6.0\n",
      "  Attempting uninstall: python-dotenv\n",
      "    Found existing installation: python-dotenv 0.21.0\n",
      "    Uninstalling python-dotenv-0.21.0:\n",
      "      Successfully uninstalled python-dotenv-0.21.0\n",
      "  Attempting uninstall: platformdirs\n",
      "    Found existing installation: platformdirs 3.10.0\n",
      "    Uninstalling platformdirs-3.10.0:\n",
      "      Successfully uninstalled platformdirs-3.10.0\n",
      "  Attempting uninstall: nest-asyncio\n",
      "    Found existing installation: nest-asyncio 1.5.6\n",
      "    Uninstalling nest-asyncio-1.5.6:\n",
      "      Successfully uninstalled nest-asyncio-1.5.6\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.4.0\n",
      "    Uninstalling fsspec-2023.4.0:\n",
      "      Successfully uninstalled fsspec-2023.4.0\n",
      "  Attempting uninstall: beautifulsoup4\n",
      "    Found existing installation: beautifulsoup4 4.12.2\n",
      "    Uninstalling beautifulsoup4-4.12.2:\n",
      "      Successfully uninstalled beautifulsoup4-4.12.2\n",
      "  Attempting uninstall: yarl\n",
      "    Found existing installation: yarl 1.8.1\n",
      "    Uninstalling yarl-1.8.1:\n",
      "      Successfully uninstalled yarl-1.8.1\n",
      "  Attempting uninstall: nltk\n",
      "    Found existing installation: nltk 3.8.1\n",
      "    Uninstalling nltk-3.8.1:\n",
      "      Successfully uninstalled nltk-3.8.1\n",
      "  Attempting uninstall: aiohttp\n",
      "    Found existing installation: aiohttp 3.8.5\n",
      "    Uninstalling aiohttp-3.8.5:\n",
      "      Successfully uninstalled aiohttp-3.8.5\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "conda-repo-cli 1.0.75 requires requests_mock, which is not installed.\n",
      "conda-repo-cli 1.0.75 requires clyent==1.2.1, but you have clyent 1.2.2 which is incompatible.\n",
      "conda-repo-cli 1.0.75 requires PyYAML==6.0.1, but you have pyyaml 6.0.2 which is incompatible.\n",
      "python-lsp-black 1.2.1 requires black>=22.3.0, but you have black 0.0 which is incompatible.\n",
      "s3fs 2023.4.0 requires fsspec==2023.4.0, but you have fsspec 2025.3.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed aiohappyeyeballs-2.6.1 aiohttp-3.11.18 banks-2.1.2 beautifulsoup4-4.13.4 deprecated-1.2.18 dirtyjson-1.0.8 filetype-1.2.0 fsspec-2025.3.2 griffe-1.7.3 llama-cloud-0.1.19 llama-cloud-services-0.6.21 llama-index-0.12.34 llama-index-agent-openai-0.4.7 llama-index-cli-0.4.1 llama-index-core-0.12.34.post1 llama-index-embeddings-openai-0.3.1 llama-index-indices-managed-llama-cloud-0.6.11 llama-index-llms-openai-0.3.38 llama-index-multi-modal-llms-openai-0.4.3 llama-index-program-openai-0.3.1 llama-index-question-gen-openai-0.3.0 llama-index-readers-file-0.4.7 llama-index-readers-llama-parse-0.4.0 llama-parse-0.6.21 nest-asyncio-1.6.0 nltk-3.9.1 platformdirs-4.3.7 propcache-0.3.1 pypdf-5.4.0 python-dotenv-1.1.0 pyyaml-6.0.2 striprtf-0.0.26 tqdm-4.67.1 yarl-1.20.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87c39a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#skip this section if you have no openai api key\n",
    "import getpass\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(os.path.expanduser(\"~/Projekte/MOOC/OpenCampus/codespace/.env\"))\n",
    "\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\n",
    "        prompt=\"Enter your OpenAI API key (required if using OpenAI): \"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee07feb-7ee6-4a6f-8531-7f7770ed6671",
   "metadata": {},
   "source": [
    "Let's ask the model about if it knows about opencampus.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7100bf1a-c1bc-4928-8bba-8e71f580aac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of my last knowledge update in October 2023, \"opencampus.sh\" does not refer to a widely recognized or established platform, software, or concept. It is possible that it could be a specific project, website, or initiative that has emerged after that date, or it could be a niche term not widely documented.\n",
      "\n",
      "If \"opencampus.sh\" is a recent development, I recommend checking the latest online resources, such as official websites, forums, or social media platforms, for the most current information. If you have more context or details about what \"opencampus.sh\" refers to, I would be happy to help clarify or provide more information based on that context!\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "response = OpenAI(model=\"gpt-4o-mini\").complete(\"What is opencampus.sh \")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6c12ad-393a-4f24-802a-a2da23f9b900",
   "metadata": {},
   "source": [
    "Uhh that is kind of a bummer, it does not even know about us. Probably because opencampus.sh is only fewly mentioned on any website etc.\n",
    "\n",
    "Let's try out the new 4.1 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76759e34-856d-4e8e-8a1e-2c9b7f65f91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.llms import ChatMessage\n",
    "llm = OpenAI(model=\"gpt-4.1-mini\")\n",
    "messages = [\n",
    "    ChatMessage(role=\"system\", content=\"You are a helpful assistant.\"),\n",
    "    ChatMessage(role=\"user\", content=\"What is opencampus.sh\"),\n",
    "]\n",
    "chat_response = llm.chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3281939d-6c07-46f0-bd01-b647e8759e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: Opencampus.sh is a platform designed to provide online educational resources and tools, often focused on collaborative learning and open access to course materials. It typically offers features such as course hosting, interactive content, and community engagement for students and educators. The exact offerings and focus can vary depending on the specific implementation or organization behind opencampus.sh.\n",
      "\n",
      "If you have a particular context or website in mind, please provide more details so I can give a more precise explanation.\n"
     ]
    }
   ],
   "source": [
    "print(chat_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b1b618-d33f-45fc-8f6e-70283488fbb0",
   "metadata": {},
   "source": [
    "Hmm seems to go a bit into hallucinations here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681ec06c-f4df-4894-8c06-69527c03494c",
   "metadata": {},
   "source": [
    "## Olama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0033ab4b-9ff1-43d9-ad66-32651fd65c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index-llms-ollama\n",
      "  Obtaining dependency information for llama-index-llms-ollama from https://files.pythonhosted.org/packages/33/1d/f000f50525dff87e6a78d7d7623720fdfc14b95a04b25e2bc4e936af2907/llama_index_llms_ollama-0.5.4-py3-none-any.whl.metadata\n",
      "  Downloading llama_index_llms_ollama-0.5.4-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.4 in /Users/user001/anaconda3/lib/python3.11/site-packages (from llama-index-llms-ollama) (0.12.34.post1)\n",
      "Requirement already satisfied: ollama>=0.4.3 in /Users/user001/anaconda3/lib/python3.11/site-packages (from llama-index-llms-ollama) (0.4.8)\n",
      "Requirement already satisfied: aiohttp<4,>=3.8.6 in /Users/user001/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (3.11.18)\n",
      "Requirement already satisfied: banks<3,>=2.0.0 in /Users/user001/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (2.1.2)\n",
      "Requirement already satisfied: dataclasses-json in /Users/user001/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/user001/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /Users/user001/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (1.0.8)\n",
      "Requirement already satisfied: filetype<2,>=1.2.0 in /Users/user001/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/user001/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (2025.3.2)\n",
      "Requirement already satisfied: httpx in /Users/user001/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (0.27.0)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /Users/user001/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/user001/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (3.1)\n",
      "Requirement already satisfied: nltk>3.8.1 in /Users/user001/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (3.9.1)\n",
      "Requirement already satisfied: numpy in /Users/user001/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (2.2.5)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Users/user001/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (10.0.1)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in /Users/user001/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (2.11.3)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in /Users/user001/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in /Users/user001/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (2.31.0)\n",
      "Requirement already satisfied: sqlalchemy[asyncio]>=1.4.49 in /Users/user001/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (2.0.35)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /Users/user001/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (8.2.2)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /Users/user001/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5,>=4.66.1 in /Users/user001/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/user001/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (4.13.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/user001/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /Users/user001/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (1.14.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/user001/anaconda3/lib/python3.11/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/user001/anaconda3/lib/python3.11/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/user001/anaconda3/lib/python3.11/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (22.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/user001/anaconda3/lib/python3.11/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/user001/anaconda3/lib/python3.11/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (6.0.2)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/user001/anaconda3/lib/python3.11/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/user001/anaconda3/lib/python3.11/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (1.20.0)\n",
      "Requirement already satisfied: griffe in /Users/user001/anaconda3/lib/python3.11/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (1.7.3)\n",
      "Requirement already satisfied: jinja2 in /Users/user001/anaconda3/lib/python3.11/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (3.1.2)\n",
      "Requirement already satisfied: platformdirs in /Users/user001/anaconda3/lib/python3.11/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (4.3.7)\n",
      "Requirement already satisfied: anyio in /Users/user001/anaconda3/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (3.5.0)\n",
      "Requirement already satisfied: certifi in /Users/user001/anaconda3/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/user001/anaconda3/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (1.0.5)\n",
      "Requirement already satisfied: idna in /Users/user001/anaconda3/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (3.4)\n",
      "Requirement already satisfied: sniffio in /Users/user001/anaconda3/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (1.2.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/user001/anaconda3/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (0.14.0)\n",
      "Requirement already satisfied: click in /Users/user001/anaconda3/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (8.1.8)\n",
      "Requirement already satisfied: joblib in /Users/user001/anaconda3/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/user001/anaconda3/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (2022.7.9)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/user001/anaconda3/lib/python3.11/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /Users/user001/anaconda3/lib/python3.11/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/user001/anaconda3/lib/python3.11/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/user001/anaconda3/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/user001/anaconda3/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (1.26.16)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/user001/anaconda3/lib/python3.11/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (2.0.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/user001/anaconda3/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/user001/anaconda3/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (3.22.0)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/user001/anaconda3/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (24.2)\n",
      "Requirement already satisfied: colorama>=0.4 in /Users/user001/anaconda3/lib/python3.11/site-packages (from griffe->banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/user001/anaconda3/lib/python3.11/site-packages (from jinja2->banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (2.1.1)\n",
      "Downloading llama_index_llms_ollama-0.5.4-py3-none-any.whl (7.8 kB)\n",
      "Installing collected packages: llama-index-llms-ollama\n",
      "Successfully installed llama-index-llms-ollama-0.5.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install llama-index-llms-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c2e6417-107c-449e-8cf1-9db4a981348f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: Okay, let's break down what OpenCampus.sh is all about.\n",
      "\n",
      "**OpenCampus.sh is a decentralized, open-source, and collaborative platform designed to create a more democratic and transparent learning environment for online education.**  It's essentially a digital \"campus\" for online courses and learning communities.\n",
      "\n",
      "Here's a breakdown of its key aspects and what makes it unique:\n",
      "\n",
      "**1. Decentralization & Blockchain Integration:**\n",
      "\n",
      "* **Blockchain Technology:** The core of OpenCampus.sh is built on blockchain technology. This means that learning certificates, courses, and even some aspects of the platform’s governance are recorded on a blockchain.  This creates a verifiable and tamper-proof record of who earned what.\n",
      "* **Self-Sovereign Identity:** Users can control their own digital identity and credentials.  Instead of relying solely on a central authority (like a university), OpenCampus.sh allows learners to demonstrate their skills and knowledge in a decentralized way.\n",
      "\n",
      "**2. Key Features & Functionality:**\n",
      "\n",
      "* **Digital Certificates (e-Certs):**  This is their primary offering.  Learners can issue and validate digital certificates for their completed courses and skills. These certificates are verifiable on the blockchain, making them trustworthy and easily transferable.\n",
      "* **Course & Learning Community Management:**  OpenCampus.sh allows course creators to manage their courses, track student progress, and foster a community around the content.\n",
      "* **Peer Review & Validation:**  The platform encourages peer review and validation of courses, helping to ensure quality and credibility.  Learners can vouch for the authenticity of a course.\n",
      "* **Decentralized Governance:**  OpenCampus.sh aims to give learners a voice in how the platform is governed, potentially through voting on changes and improvements.\n",
      "* **Skill Verification:** It’s designed to help validate skills and certifications for career advancement.\n",
      "\n",
      "**3.  Why is it significant?**\n",
      "\n",
      "* **Combats Fake Certificates:**  A major challenge in online learning is the prevalence of fake certificates. OpenCampus.sh is tackling this issue by providing a verifiable, blockchain-based record.\n",
      "* **Increased Trust & Transparency:** Blockchain technology enhances trust and transparency in online learning.\n",
      "* **Empowerment of Learners:** It gives learners more control over their learning journey and credentials.\n",
      "* **Potential for a New Model for Education:**  It’s exploring a shift from traditional, centralized learning models towards a more decentralized and community-driven approach.\n",
      "\n",
      "\n",
      "**4.  Who is it for?**\n",
      "\n",
      "* **Individuals:** Learners, professionals, and anyone seeking to validate their skills and certifications.\n",
      "* **Educators:**  Creating and managing courses.\n",
      "* **Organizations:**  Institutions offering online courses and certifications.\n",
      "\n",
      "\n",
      "**Resources:**\n",
      "\n",
      "* **Official Website:** [https://opencampus.sh/](https://opencampus.sh/)\n",
      "\n",
      "**In short, OpenCampus.sh is a bold experiment in creating a more trustworthy and empowering system for online learning, leveraging blockchain technology to build a decentralized ecosystem.**\n",
      "\n",
      "---\n",
      "\n",
      "**Do you have any specific questions about OpenCampus.sh that you'd like me to answer? For example:**\n",
      "\n",
      "*   Are you interested in a particular aspect of the platform (like the certificates)?\n",
      "*   Would you like me to explain how it works in more detail?\n",
      "*   Are you wondering about its potential impact on the industry?\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.core.llms import ChatMessage\n",
    "\n",
    "llm = Ollama(model=\"gemma3:1b\", request_timeout=60.0)\n",
    "\n",
    "messages = [\n",
    "    ChatMessage(role=\"system\", content=\"You are a helpful assistant.\"),\n",
    "    ChatMessage(role=\"user\", content=\"What is opencampus.sh\"),\n",
    "]\n",
    "\n",
    "chat_response = llm.chat(messages)\n",
    "print(chat_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0149a62e-d2ca-4d70-82cc-586e7c1baafe",
   "metadata": {},
   "source": [
    "Oh dear.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1a71c5-25ce-4d7a-8bc8-82a2c65bd465",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We have libraries which wrap the llm call into functions and classes of their liking. We gain that we can easily switch between different model providers but loose at lot of flexibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec892f8-1dd8-44b4-a470-008e0922435c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
